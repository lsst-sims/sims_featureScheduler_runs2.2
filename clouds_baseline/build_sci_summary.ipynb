{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a big pandas dataframe to hold all the metric values we're interested in, so then we can pass it around and plot it up any way we like\n",
    "\n",
    "I guess depth in each filter for each DDF?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I just coppied them over from hyak and sym linked them to this directory for ease of use\n",
    "glance_dirs = glob.glob('./*10yrs_glance')\n",
    "sci_dirs = glob.glob('./*_sci')\n",
    "\n",
    "glance_dirs.sort()\n",
    "sci_dirs.sort()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./baseline_v2.2_10yrs_sci',\n",
       " './clouds_baseline_cloudso0_ns2_v2.2_10yrs_sci',\n",
       " './clouds_baseline_cloudso0_ns3_v2.2_10yrs_sci',\n",
       " './clouds_baseline_cloudso10_ns2_v2.2_10yrs_sci',\n",
       " './clouds_baseline_cloudso10_ns3_v2.2_10yrs_sci',\n",
       " './clouds_baseline_cloudso11_ns2_v2.2_10yrs_sci',\n",
       " './clouds_baseline_cloudso11_ns3_v2.2_10yrs_sci',\n",
       " './clouds_baseline_cloudso1_ns2_v2.2_10yrs_sci',\n",
       " './clouds_baseline_cloudso1_ns3_v2.2_10yrs_sci',\n",
       " './clouds_baseline_cloudso20_ns2_v2.2_10yrs_sci',\n",
       " './clouds_baseline_cloudso20_ns3_v2.2_10yrs_sci',\n",
       " './clouds_baseline_cloudso21_ns2_v2.2_10yrs_sci',\n",
       " './clouds_baseline_cloudso21_ns3_v2.2_10yrs_sci',\n",
       " './clouds_baseline_cloudso30_ns2_v2.2_10yrs_sci',\n",
       " './clouds_baseline_cloudso30_ns3_v2.2_10yrs_sci',\n",
       " './clouds_baseline_cloudso31_ns2_v2.2_10yrs_sci',\n",
       " './clouds_baseline_cloudso31_ns3_v2.2_10yrs_sci',\n",
       " './clouds_baseline_cloudso35_ns2_v2.2_10yrs_sci',\n",
       " './clouds_baseline_cloudso35_ns3_v2.2_10yrs_sci',\n",
       " './clouds_baseline_cloudso36_ns2_v2.2_10yrs_sci',\n",
       " './clouds_baseline_cloudso36_ns3_v2.2_10yrs_sci']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sci_dirs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./baseline_v2.2_10yrs_glance',\n",
       " './clouds_baseline_cloudso0_ns2_v2.2_10yrs_glance',\n",
       " './clouds_baseline_cloudso0_ns3_v2.2_10yrs_glance',\n",
       " './clouds_baseline_cloudso10_ns2_v2.2_10yrs_glance',\n",
       " './clouds_baseline_cloudso10_ns3_v2.2_10yrs_glance',\n",
       " './clouds_baseline_cloudso11_ns2_v2.2_10yrs_glance',\n",
       " './clouds_baseline_cloudso11_ns3_v2.2_10yrs_glance',\n",
       " './clouds_baseline_cloudso1_ns2_v2.2_10yrs_glance',\n",
       " './clouds_baseline_cloudso1_ns3_v2.2_10yrs_glance',\n",
       " './clouds_baseline_cloudso20_ns2_v2.2_10yrs_glance',\n",
       " './clouds_baseline_cloudso20_ns3_v2.2_10yrs_glance',\n",
       " './clouds_baseline_cloudso21_ns2_v2.2_10yrs_glance',\n",
       " './clouds_baseline_cloudso21_ns3_v2.2_10yrs_glance',\n",
       " './clouds_baseline_cloudso30_ns2_v2.2_10yrs_glance',\n",
       " './clouds_baseline_cloudso30_ns3_v2.2_10yrs_glance',\n",
       " './clouds_baseline_cloudso31_ns2_v2.2_10yrs_glance',\n",
       " './clouds_baseline_cloudso31_ns3_v2.2_10yrs_glance',\n",
       " './clouds_baseline_cloudso35_ns2_v2.2_10yrs_glance',\n",
       " './clouds_baseline_cloudso35_ns3_v2.2_10yrs_glance',\n",
       " './clouds_baseline_cloudso36_ns2_v2.2_10yrs_glance',\n",
       " './clouds_baseline_cloudso36_ns3_v2.2_10yrs_glance']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glance_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = [name.replace('./', '').replace('_glance', '') for name in glance_dirs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "runNames =  [name[2:].replace('_v2.2_10yrs_glance','').replace('v2.2_10yrs_glance','').replace('v2.2_10yrs_glance','') for name in glance_dirs] \n",
    "versions = ['2.1']*len(glance_dirs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['baseline',\n",
       " 'clouds_baseline_cloudso0_ns2',\n",
       " 'clouds_baseline_cloudso0_ns3',\n",
       " 'clouds_baseline_cloudso10_ns2',\n",
       " 'clouds_baseline_cloudso10_ns3',\n",
       " 'clouds_baseline_cloudso11_ns2',\n",
       " 'clouds_baseline_cloudso11_ns3',\n",
       " 'clouds_baseline_cloudso1_ns2',\n",
       " 'clouds_baseline_cloudso1_ns3',\n",
       " 'clouds_baseline_cloudso20_ns2',\n",
       " 'clouds_baseline_cloudso20_ns3',\n",
       " 'clouds_baseline_cloudso21_ns2',\n",
       " 'clouds_baseline_cloudso21_ns3',\n",
       " 'clouds_baseline_cloudso30_ns2',\n",
       " 'clouds_baseline_cloudso30_ns3',\n",
       " 'clouds_baseline_cloudso31_ns2',\n",
       " 'clouds_baseline_cloudso31_ns3',\n",
       " 'clouds_baseline_cloudso35_ns2',\n",
       " 'clouds_baseline_cloudso35_ns3',\n",
       " 'clouds_baseline_cloudso36_ns2',\n",
       " 'clouds_baseline_cloudso36_ns3']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the dataframe\n",
    "df = pd.DataFrame(np.array([runNames, versions]).T, columns=['runName', 'version'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of tupes with (metricName, summaryName) that we want to pull from glance dirs\n",
    "mnamesname =[('parallax', 'best18k'),\n",
    "            ('properMotion', 'best18k'),\n",
    "            ('fO', 'fONv MedianNvis'),\n",
    "            ('fO', 'fOArea')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for names in mnamesname:\n",
    "    column_vals = []\n",
    "    sql = 'select summaryValue from summarystats where metricId = (select metricId from metrics where metricName = \"%s\") and summaryName= \"%s\";' % (names[0], names[1])\n",
    "    for directory in glance_dirs:\n",
    "        conn = sqlite3.connect(directory+'/resultsDb_sqlite.db')\n",
    "        result = pd.read_sql(sql, conn).values.ravel()\n",
    "        if np.size(result) > 1:\n",
    "            ValueError\n",
    "        else:\n",
    "            column_vals.append(np.max(result))\n",
    "        conn.close()\n",
    "    df[names[0]+'_'+names[1]] = column_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the median coadded depths in each filter\n",
    "for filtername in 'ugrizy':\n",
    "    column_vals = []\n",
    "    sql = 'select summaryValue from summarystats where metricId = (select metricId from metrics where metricName = \"CoaddM5\" and metricInfoLabel=\"%s\") and summaryName= \"Median\";' % (filtername)\n",
    "    for directory in glance_dirs:\n",
    "        conn = sqlite3.connect(directory+'/resultsDb_sqlite.db')\n",
    "        result = pd.read_sql(sql, conn).values.ravel()\n",
    "        if np.size(result) > 1:\n",
    "            ValueError\n",
    "        else:\n",
    "            column_vals.append(np.max(result))\n",
    "        conn.close()\n",
    "    df['median_coadd_%s' % filtername] = column_vals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of tupes with (metricName, summaryName) that we want to pull from science dirs\n",
    "mnamesname =[('SNNSNMetric_nSN', 'Total detected'),\n",
    "            ('MicrolensingMetric_detect', 'Fraction detected of total (mean)'),\n",
    "            ('KNePopMetric_all__multi_color_detect', 'Fraction detected of total (mean)'),\n",
    "            ('GalaxyCountsMetric_extended', 'N Galaxies (all)'),\n",
    "            ('TDEsPopMetric__some_color', 'Fraction detected of total (mean)'),\n",
    "             ('TDEsPopMetric__some_color_pu', 'Fraction detected of total (mean)'), \n",
    "            ('WeakLensingNvisits', 'Median')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for names in mnamesname:\n",
    "    column_vals = []\n",
    "    sql = 'select summaryValue from summarystats where metricId = (select metricId from metrics where metricName = \"%s\") and summaryName= \"%s\";' % (names[0], names[1])\n",
    "    for directory in sci_dirs:\n",
    "        conn = sqlite3.connect(directory+'/resultsDb_sqlite.db')\n",
    "        result = pd.read_sql(sql, conn).values.ravel()\n",
    "        if np.size(result) > 1:\n",
    "            ValueError\n",
    "        else:\n",
    "            column_vals.append(np.max(result))\n",
    "        conn.close()\n",
    "    df[names[0]+'_'+names[1]] = column_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "mnamesname =[('ExgalM5_with_cuts', '3x2ptFoM')]\n",
    "\n",
    "for names in mnamesname:\n",
    "    column_vals = []\n",
    "    sql = 'select summaryValue from summarystats where metricId = (select metricId from metrics where metricName = \"%s\" and metricInfoLabel=\"i band non-DD year 10\") and summaryName= \"%s\";' % (names[0], names[1])\n",
    "    for directory in sci_dirs:\n",
    "        conn = sqlite3.connect(directory+'/resultsDb_sqlite.db')\n",
    "        result = pd.read_sql(sql, conn).values.ravel()\n",
    "        if np.size(result) > 1:\n",
    "            ValueError\n",
    "        else:\n",
    "            try:\n",
    "                column_vals.append(np.max(result))\n",
    "            except:\n",
    "                import pdb ;pdb.set_trace()\n",
    "        conn.close()\n",
    "    df[names[0]+'_'+names[1]] = column_vals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'select summaryValue from summarystats where metricId = (select metricId from metrics where metricName = \"ExgalM5_with_cuts\" and metricInfoLabel=\"i band non-DD year 10\") and summaryName= \"3x2ptFoM\";'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n# Pull the DDF depths from everywhere. \\nfilters = \\'ugrizy\\'\\nddf_names = [\\'DD:ELAISS1\\', \\'DD:XMM-LSS\\', \\'DD:ECDFS\\', \\'DD:COSMOS\\', \\'DD:EDFSa\\', \\'DD:EDFSb\\']\\n\\nfor filtername in filters:\\n    for ddf_name in ddf_names:\\n        column_vals = []\\n        sql = \\'select summaryValue from summarystats where summaryName=\"Median depth %s, %s\"\\' % (ddf_name, filtername)\\n        for directory in sci_dirs:\\n            conn = sqlite3.connect(directory+\\'/resultsDb_sqlite.db\\')\\n            result = pd.read_sql(sql, conn).values.ravel()\\n            if np.size(result) > 1:\\n                ValueError\\n            else:\\n                column_vals.append(np.max(result))\\n            conn.close()\\n        df[ddf_name+\\',\\'+filtername] = column_vals\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "# Pull the DDF depths from everywhere. \n",
    "filters = 'ugrizy'\n",
    "ddf_names = ['DD:ELAISS1', 'DD:XMM-LSS', 'DD:ECDFS', 'DD:COSMOS', 'DD:EDFSa', 'DD:EDFSb']\n",
    "\n",
    "for filtername in filters:\n",
    "    for ddf_name in ddf_names:\n",
    "        column_vals = []\n",
    "        sql = 'select summaryValue from summarystats where summaryName=\"Median depth %s, %s\"' % (ddf_name, filtername)\n",
    "        for directory in sci_dirs:\n",
    "            conn = sqlite3.connect(directory+'/resultsDb_sqlite.db')\n",
    "            result = pd.read_sql(sql, conn).values.ravel()\n",
    "            if np.size(result) > 1:\n",
    "                ValueError\n",
    "            else:\n",
    "                column_vals.append(np.max(result))\n",
    "            conn.close()\n",
    "        df[ddf_name+','+filtername] = column_vals\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "unable to open database file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m trojan \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m filenames:\n\u001b[0;32m---> 17\u001b[0m     conn \u001b[38;5;241m=\u001b[39m \u001b[43msqlite3\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[38;5;124;43m_ss/resultsDb_sqlite.db\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     sql \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mselect summaryValue from summarystats where summaryName=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDifferentialCompleteness H = 16.000000\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m     19\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetricId = (select metricId from metrics where metricName =\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDiscovery_N_Chances\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m and metricMetadata=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNEO 3 pairs in 15 nights detection loss\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     20\u001b[0m     val \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmax(pd\u001b[38;5;241m.\u001b[39mread_sql(sql, conn)\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mravel())\n",
      "\u001b[0;31mOperationalError\u001b[0m: unable to open database file"
     ]
    }
   ],
   "source": [
    "# Now to pull things from the solar system results\n",
    "\n",
    "# here's what we used last time:\n",
    "#'3 pairs in 15 nights detection loss NEO H=16.0',\n",
    "#        '3 pairs in 30 nights detection loss NEO H=22.0',\n",
    "#       '3 pairs in 15 nights detection loss TNO H=4.0'\n",
    "\n",
    "faint_neo = []\n",
    "bright_neo = []\n",
    "tno = []\n",
    "\n",
    "pha = []\n",
    "mba = []\n",
    "trojan = []\n",
    "\n",
    "for name in filenames:\n",
    "    conn = sqlite3.connect('%s_ss/resultsDb_sqlite.db' % name)\n",
    "    sql = 'select summaryValue from summarystats where summaryName=\"DifferentialCompleteness H = 16.000000\" and '+\\\n",
    "        'metricId = (select metricId from metrics where metricName =\"Discovery_N_Chances\" and metricMetadata=\"NEO 3 pairs in 15 nights detection loss\")'\n",
    "    val = np.max(pd.read_sql(sql, conn).values.ravel())\n",
    "    bright_neo.append(val)\n",
    "    \n",
    "    \n",
    "    sql = 'select summaryValue from summarystats where summaryName=\"DifferentialCompleteness H = 22.000000\" and '+\\\n",
    "        'metricId = (select metricId from metrics where metricName =\"Discovery_N_Chances\" and metricMetadata=\"NEO 3 pairs in 15 nights detection loss\")'\n",
    "\n",
    "    val = np.max(pd.read_sql(sql, conn).values.ravel())\n",
    "    faint_neo.append(val)\n",
    "    \n",
    "    #conn.close()\n",
    "    #conn = sqlite3.connect('%s_l7_5k/resultsDb_sqlite.db' % name)\n",
    "    \n",
    "    sql = 'select summaryValue from summarystats where summaryName=\"DifferentialCompleteness H = 6.000000\" and '+\\\n",
    "          'metricId = (select metricId from metrics where metricName =\"Discovery_N_Chances\" and metricMetadata=\"TNO 3 pairs in 15 nights detection loss\")'\n",
    "\n",
    "    try:\n",
    "        val = np.max(pd.read_sql(sql, conn).values.ravel())\n",
    "    except:\n",
    "        print(name)\n",
    "        val = 0\n",
    "    tno.append(val)\n",
    "    \n",
    "    \n",
    "    sql = 'select summaryValue from summarystats where summaryName=\"DifferentialCompleteness H = 22.000000\" and '+\\\n",
    "        'metricId = (select metricId from metrics where metricName =\"Discovery_N_Chances\" and metricMetadata=\"PHA 3 pairs in 15 nights detection loss\")'\n",
    "    val = np.max(pd.read_sql(sql, conn).values.ravel())\n",
    "    pha.append(val)\n",
    "    \n",
    "    try:\n",
    "        sql = 'select summaryValue from summarystats where summaryName=\"DifferentialCompleteness H = 22.000000\" and '+\\\n",
    "            'metricId = (select metricId from metrics where metricName =\"Discovery_N_Chances\" and metricMetadata=\"MBA 3 pairs in 15 nights detection loss\")'\n",
    "        val = np.max(pd.read_sql(sql, conn).values.ravel())\n",
    "        mba.append(val)\n",
    "    except:\n",
    "        print(name)\n",
    "        val = 0\n",
    "    \n",
    "    sql = 'select summaryValue from summarystats where summaryName=\"DifferentialCompleteness H = 15.000000\" and '+\\\n",
    "        'metricId = (select metricId from metrics where metricName =\"Discovery_N_Chances\" and metricMetadata=\"Trojan 3 pairs in 15 nights detection loss\")'\n",
    "    val = np.max(pd.read_sql(sql, conn).values.ravel())\n",
    "    trojan.append(val)\n",
    "    \n",
    "    \n",
    "    conn.close()\n",
    "    \n",
    "df['NEO bright'] = bright_neo\n",
    "df['NEO faint'] = faint_neo \n",
    "df['TNO'] = tno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['NEO faint']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['NEO bright']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TNO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runNames[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df['median_coadd_g'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle would be much smaller, but I guess can zip after if we want to\n",
    "df.to_hdf('combined_maf_dataframe.hdf', 'maf')\n",
    "# restore with:\n",
    "# df = pd.read_hdf('combined_maf_dataframe.hdf', 'maf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
